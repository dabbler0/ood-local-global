{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "assumed-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, './transformers')\n",
    "import nltk\n",
    "tokenizer = nltk.NLTKWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proprietary-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model_from(root):\n",
    "    checkpoints = os.listdir(root)\n",
    "    print(checkpoints)\n",
    "    best = min(checkpoints, key = lambda x: float(x.split('loss-')[1].split('.pt')[0]))\n",
    "    loss = float(best.split('loss-')[1].split('.')[0])\n",
    "    print('Loading', os.path.join(root, best), best)\n",
    "    return torch.load(os.path.join(root, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "resistant-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load('/raid/lingo/abau/lm/vocab.en.1m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fiscal-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_topk(vec):\n",
    "    v, inds = torch.topk(vec.squeeze(), 10)\n",
    "    print([vocab[i - 2][0] if i > 1 else '<unk>' for i in inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unsigned-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2sen(seq, vocab = vocab):\n",
    "    return ' '.join([\n",
    "        vocab[c - 2][0] if c >= 2 else\n",
    "        '<unk>' if c == 0 else\n",
    "        '<end>'\n",
    "        for c in seq\n",
    "    ])\n",
    "def sen2seq(sentence, vocab = vocab):\n",
    "    vocab_dict = { v[0]: i + 2 for i, v in enumerate(vocab) if i < 2 ** 14 - 2 }\n",
    "    tokens = [token.lower() for token in tokenizer.tokenize(sentence)]\n",
    "    inds = [vocab_dict[t] if t in vocab_dict else 0 for t in tokens]\n",
    "    return torch.LongTensor(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "constitutional-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = torch.load('/raid/lingo/abau/lm/monolingual-models/transformer-1/epoch-41.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "coastal-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_tm(sen):\n",
    "    seq = sen2seq(sen).cuda().unsqueeze(1)\n",
    "    mask = tm.generate_square_subsequent_mask(seq.size(0)).cuda()\n",
    "    return tm(seq, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "palestinian-therapy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', '<unk>', 'and', '‚Äù', 'a', 'but', 'which', 'who', 'he', 'i']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "tough-handbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11.4517, -1.7615,  9.3934,  ..., -2.4477, -0.9882, -1.9899]],\n",
       "\n",
       "        [[12.1770, -8.3277, 12.2103,  ...,  0.4048, -4.4624, -1.3171]],\n",
       "\n",
       "        [[ 9.9585, -5.1685,  6.0543,  ..., -0.9111, -0.7403, -2.4498]],\n",
       "\n",
       "        [[ 9.4421, -4.0359,  3.2801,  ..., -1.5936,  0.5246,  1.0134]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_with_tm('he walked to the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
